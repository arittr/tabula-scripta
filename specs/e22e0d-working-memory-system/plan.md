# Feature: Working Memory System - Implementation Plan

---
runId: e22e0d
feature: working-memory-system
created: 2025-11-17
status: ready
---

> **Generated by:** Task Decomposition skill
> **From spec:** specs/e22e0d-working-memory-system/spec.md
> **Created:** 2025-11-17

## Execution Summary

- **Total Tasks**: 5
- **Total Phases**: 4
- **Sequential Time**: 21h
- **Parallel Time**: 17h
- **Time Savings**: 4h (19%)

**Parallel Opportunities:**

- Phase 3: 2 tasks (4h saved - commands and hooks can be built concurrently)

---

## Phase 1: Foundation

**Strategy**: Sequential
**Reason**: Establishes plugin structure required by all subsequent tasks

### Task 1: Plugin Foundation

**Files**:
- plugin.json
- docs/setup-guide.md

**Complexity**: M (4h)

**Dependencies**: None

**Description**:
Create plugin infrastructure and setup documentation. This establishes the plugin metadata, declares dependency on obsidian-mcp-plugin, and provides user instructions for MCP configuration.

**Implementation Steps**:

1. Create `plugin.json` with metadata:
   - Plugin name: "tabula-scripta"
   - Description: "Working memory system for Claude Code"
   - Version: "0.1.0"
   - Requires: obsidian MCP server
   - Author, repository, license fields

2. Create `docs/setup-guide.md`:
   - Prerequisites: Obsidian, obsidian-mcp-plugin installed
   - Vault setup: `~/.claude-memory/` structure
   - MCP server configuration in Claude Code config
   - Dataview plugin setup (optional Smart Connections)
   - Testing MCP connection
   - Troubleshooting common issues

3. Verify plugin.json follows Claude Code plugin spec
4. Test MCP connection validation logic

**Acceptance Criteria**:

- [ ] plugin.json contains all required metadata fields
- [ ] plugin.json declares obsidian-mcp-plugin dependency
- [ ] setup-guide.md covers vault creation, MCP config, testing
- [ ] setup-guide.md includes troubleshooting section
- [ ] Documentation references correct vault paths (~/.claude-memory/)

**Quality Gates**:

```bash
# Validate JSON syntax
cat plugin.json | jq .

# Check file structure
ls -la docs/setup-guide.md
```

---

## Phase 2: Core Skill

**Strategy**: Sequential
**Reason**: Depends on Phase 1 plugin structure; required by Phase 3 components

### Task 2: Core Memory Skill

**Files**:
- skills/managing-working-memory.md

**Complexity**: L (6h)

**Dependencies**: task-1 (requires plugin.json structure)

**Description**:
Implement the core `managing-working-memory` skill that defines when/what/how to write memories. This is the most complex component, containing all write triggers, note templates, conflict detection, and cross-project promotion logic.

**Implementation Steps**:

1. Define skill header and overview:
   - When to use (automatic triggers + ask-first triggers)
   - Integration with superpowers skills (code-review, debugging, brainstorming)
   - Memory granularity (session/entity/topic)

2. Implement write triggers section:
   - Automatic: After code review, debugging, architectural decision, periodic checkpoints (30-60 min), session end
   - Ask-first: User preferences, contradictions to existing notes, global entity creation
   - Memory spam prevention: <5 writes per hour-long session

3. Create note templates with frontmatter:
   - Session note template (temporal, ephemeral)
   - Entity note template (persistent, specific)
   - Topic note template (organizational)
   - All templates include: type, project, tags, created, updated, status, claude_last_accessed, cross_project_recalls

4. Implement living memory update logic:
   - Patch operations (append to sections, preserve existing content)
   - Conflict detection (timestamp comparison: updated vs claude_last_accessed)
   - Conflict resolution flow: Show diff, ask user to merge/abort/discuss

5. Add cross-project pattern detection:
   - Track when entity from project A recalled in project B
   - Log to cross_project_recalls frontmatter array
   - After 3 cross-project recalls → ask user to promote to global entity

6. Define MCP operation patterns:
   - create_note, read_note, update_note, search_notes, graph_query, dataview_query
   - Error handling for MCP unavailable
   - Graceful degradation fallbacks

7. Add TodoWrite integration examples:
   - Memory checkpoint checklist
   - Session end checklist
   - Compaction checklist

**Acceptance Criteria**:

- [ ] Skill defines all automatic and ask-first triggers clearly
- [ ] All three note templates (session/entity/topic) include complete frontmatter schema
- [ ] Conflict detection logic compares timestamps correctly
- [ ] Cross-project recall tracking increments counter and prompts at threshold
- [ ] MCP operations have error handling and graceful degradation
- [ ] Memory spam prevention logic limits writes to <5 per hour
- [ ] TodoWrite checklists cover memory checkpoint, session end, compaction

**Quality Gates**:

```bash
# Validate markdown syntax
ls -la skills/managing-working-memory.md

# Verify frontmatter examples are valid YAML
# (Extract and validate each template's frontmatter)
```

---

## Phase 3: Interface Layer

**Strategy**: Parallel
**Reason**: Manual commands and session hooks are independent; both invoke the core skill from Phase 2

### Task 3: Manual Commands

**Files**:
- commands/remember.md
- commands/recall.md
- commands/update-memory.md

**Complexity**: M (5h)

**Dependencies**: task-2 (commands invoke managing-working-memory skill)

**Description**:
Implement manual slash commands for user-driven memory operations. These provide the Phase 1 MVP interface before autonomous triggers are enabled.

**Implementation Steps**:

1. Create `/remember` command:
   - Parse arguments: [type] [title]
   - Validate type (session/entity/topic)
   - Detect project context from git repo / working directory
   - Generate frontmatter with timestamps
   - Invoke MCP create_note operation
   - Confirm note created at correct vault path
   - Show wikilink for easy reference

2. Create `/recall` command:
   - Parse query argument
   - Attempt semantic search via Smart Connections (if available)
   - Fallback to text search via MCP search_notes
   - Filter by project context (or include global entities)
   - Present results with relevance ranking
   - Limit to top 5 results (not overwhelming)
   - Offer to load full note content on demand

3. Create `/update-memory` command:
   - Parse title argument
   - Load existing note via MCP read_note
   - Check timestamps: updated vs claude_last_accessed
   - If conflict detected: Show diff, ask user to merge/abort/discuss
   - If clean: Apply patch operation (append/update sections)
   - Update frontmatter: updated timestamp, claude_last_accessed
   - Invoke MCP update_note operation
   - Confirm update successful

4. Add error handling:
   - MCP unavailable → graceful message
   - Note not found → offer to create
   - Invalid type/title → validation error

**Acceptance Criteria**:

- [ ] `/remember` creates notes at correct vault path with valid frontmatter
- [ ] `/recall` finds notes via search and presents top 5 results
- [ ] `/update-memory` detects conflicts via timestamp comparison
- [ ] All commands handle MCP unavailable gracefully
- [ ] Commands detect project context correctly from git repo
- [ ] Wikilinks `[[Entity]]` are generated correctly

**Quality Gates**:

```bash
# Validate command files exist
ls -la commands/remember.md commands/recall.md commands/update-memory.md

# Test with real MCP connection (manual verification)
```

---

### Task 4: Session Hooks

**Files**:
- hooks/session-start.md
- hooks/session-end.md

**Complexity**: M (4h)

**Dependencies**: task-2 (hooks invoke managing-working-memory skill)

**Description**:
Implement session lifecycle hooks for proactive recall and autonomous compaction. These enable Phase 2 (proactive recall) and Phase 3 (autonomous management) functionality.

**Implementation Steps**:

1. Create `session-start.md` hook:
   - Detect project context from git repo / working directory
   - Load project index via MCP read_note (~/.claude-memory/claude/projects/{project}/_index.md)
   - Query last 3 session notes via Dataview (sorted by created desc)
   - Load linked entities from project index
   - Generate 1-3 sentence summary (not full memory dump)
   - Present summary to user
   - Offer to load additional context on request
   - Performance target: <2 seconds

2. Create `session-end.md` hook:
   - Check current session note length (if exists)
   - Check session note age (created timestamp)
   - Threshold: 500 lines OR 3 days old (whichever first)
   - If threshold met: Trigger compaction flow
   - Compaction: Parse session → extract knowledge → update entity notes → archive session
   - Archive location: ~/.claude-memory/claude/projects/{project}/archive/sessions/
   - Never delete notes (archive preserves history)

3. Add project detection logic:
   - Check git repo (git rev-parse --show-toplevel)
   - Extract project name from directory
   - Fallback to "default" if not in git repo

4. Implement Dataview query patterns:
   - Query last N session notes: `LIST FROM "claude/projects/{project}/sessions" SORT created DESC LIMIT 3`
   - Query active entities: `LIST FROM "claude/projects/{project}/entities" WHERE status = "active"`

5. Add summary generation logic:
   - Extract key highlights from session notes
   - Limit to 1-3 sentences
   - Focus on recent decisions, patterns, blockers

**Acceptance Criteria**:

- [ ] session-start hook loads project context automatically
- [ ] Summary is 1-3 sentences (not overwhelming)
- [ ] Last 3 session notes loaded via Dataview query
- [ ] Project detection works for git repos and non-git directories
- [ ] User can request additional context after summary
- [ ] session-end hook compacts at threshold (500 lines OR 3 days)
- [ ] Compacted notes archived (not deleted) at correct path
- [ ] Performance: Session start recall <2 seconds

**Quality Gates**:

```bash
# Validate hook files exist
ls -la hooks/session-start.md hooks/session-end.md

# Test Dataview query syntax (manual verification in Obsidian)
```

---

## Phase 4: Documentation

**Strategy**: Sequential
**Reason**: Depends on all previous phases to document complete patterns

### Task 5: Documentation & Patterns

**Files**:
- docs/memory-patterns.md

**Complexity**: S (2h)

**Dependencies**: task-2, task-3, task-4 (documents patterns from skill, commands, hooks)

**Description**:
Create comprehensive usage patterns and examples showing how to use the working memory system effectively. This completes the documentation suite started in Task 1.

**Implementation Steps**:

1. Create `docs/memory-patterns.md`:
   - Overview of three-layer memory granularity
   - When to use session vs entity vs topic notes
   - Example workflows for common scenarios

2. Add pattern examples:
   - Pattern 1: Debugging session → entity update
   - Pattern 2: Architecture decision → topic note
   - Pattern 3: Code review → entity refinement
   - Pattern 4: Cross-project pattern promotion

3. Document skill integration patterns:
   - How managing-working-memory integrates with requesting-code-review
   - How it integrates with systematic-debugging
   - How it integrates with brainstorming

4. Add conflict resolution examples:
   - Clean update (no conflict)
   - Human edit conflict (show diff, merge)
   - Major rewrite conflict (abort, discuss)

5. Include frontmatter examples:
   - Session note frontmatter
   - Entity note frontmatter
   - Topic note frontmatter
   - Cross-project recall tracking

6. Add troubleshooting section:
   - MCP connection issues
   - Vault not found
   - Conflict resolution stuck
   - Memory spam (too many writes)

**Acceptance Criteria**:

- [ ] memory-patterns.md covers all three note types (session/entity/topic)
- [ ] Examples show integration with superpowers skills
- [ ] Conflict resolution flows documented with examples
- [ ] Frontmatter examples match schema from skill
- [ ] Troubleshooting section addresses common issues

**Quality Gates**:

```bash
# Validate documentation files exist
ls -la docs/memory-patterns.md docs/setup-guide.md

# Check for broken internal links
# (Manual review of wikilinks and references)
```

---

## Testing Strategy

**Phase 1 (MVP - Manual Commands):**
- Manual testing: Create/recall/update notes via commands
- Verify notes appear in Obsidian vault
- Test conflict detection with manual file edits
- Validate frontmatter schema

**Phase 2 (Proactive Recall):**
- Test session-start hook with real project
- Verify Dataview queries return correct results
- Measure performance (<2s target)
- Test summary generation (1-3 sentences)

**Phase 3 (Autonomous Management):**
- Test skill triggers with code-review, debugging workflows
- Verify compaction threshold detection
- Test archival (not deletion)
- Validate cross-project recall tracking
- Test global promotion prompt

**Skill Testing with Subagents:**
- Use `testing-skills-with-subagents` skill to validate managing-working-memory
- Test TodoWrite checklists (memory checkpoint, session end, compaction)
- Verify conflict resolution flows
- Ensure memory spam prevention works

---

## Risk Mitigation

**Risk 1: MCP Connection Failure**
- Mitigation: Graceful degradation, clear error messages
- Testing: Simulate MCP unavailable scenarios

**Risk 2: Conflict Detection False Positives**
- Mitigation: Show diff before overwriting, user confirmation
- Testing: Test various conflict scenarios (clean, minor edit, major rewrite)

**Risk 3: Memory Spam**
- Mitigation: <5 writes per hour limit, threshold checks
- Testing: Simulate long sessions, verify write rate limiting

**Risk 4: Performance (Session Start)**
- Mitigation: Limit Dataview queries (last 3 sessions), parallel loading
- Testing: Measure with large vaults (>100 notes)

**Risk 5: Data Loss**
- Mitigation: Never delete (always archive), timestamp tracking
- Testing: Verify archive location, test recovery from archive

---

## Next Steps

**Review this plan:**
```bash
cat /Users/drewritter/projects/tabula-scripta/.worktrees/e22e0d-main/specs/e22e0d-working-memory-system/plan.md
```

**Execute the plan:**
```bash
/spectacular:execute @specs/e22e0d-working-memory-system/plan.md
```

**Phase execution order:**
1. Phase 1: Foundation (4h) - Sequential
2. Phase 2: Core Skill (6h) - Sequential
3. Phase 3: Interface Layer (5h) - **Parallel** (4h time savings)
4. Phase 4: Documentation (2h) - Sequential

Total implementation time: 17h (with parallelization) vs 21h (sequential)
